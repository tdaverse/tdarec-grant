---
title: "Modular, interoperable, and extensible topological data analysis in R"
subtitle: "November Progress Report"
author:
  - name: Jason Cory Brunson
    affiliations:
      - ref: uf
  - name: Aymeric Stamm
    affiliations: 
      - ref: lmjl
    corresponding: true
    orcid: 0000-0002-8725-3654
affiliations:
  - id: lmjl
    name: UMR CNRS 6629, Nantes University, Ecole Centrale de Nantes
    department: Department of Mathematics Jean Leray
    city: Nantes
    country: France
  - id: uf
    name: University of Florida
    department: Laboratory for Systems Medicine, Division of Pulmonary, Critical Care, and Sleep Medicine
    city: Gainesville
    country: United States
date: 2024 December 1
format:
    pdf: default
    html: default
toc: true
number-sections: true
bibliography: ../references.bib
---

## Proposal

This section will restate the specific aims of our proposal.
The next will provide a detailed update on each aim in turn.

Our **goal** with this project is to seamlessly integrate popular techniques from topological data analysis (TDA) into common statistical workflows in R. The **expected benefit** is that these extensions will be more widely used by non-specialist researchers and analysts, which will create sufficient awareness and interest in the community to extend the individual packages and the collection.

### Overview

The [Tidymodels](https://www.tidymodels.org/) ecosystem [@kuhn2022tidy] provides a complete toolkit for common machine learning (ML) tasks. ML relies heavily on vectorizations, and the last decade of work in TDA has produced several for topological data. Our **first aim** is to make these available in a Tidymodels-compatible R package.

TDA relies heavily on statistical inference. A variety of hypothesis tests have been proposed in the research literature and have idiosyncratic implementations. Our **second aim** is to provide a Tidymodels-compatible package for permutation-based hypothesis testing with topological data.

The primary workhorse for TDA is [Ripser](http://ripser.org/), which efficiently computes Vietoris–Rips filtrations. The engine used in the lightweight wrapper package [{ripserr}](https://cran.r-project.org/package=ripserr) is missing key features, so our **third aim** is to upgrade it.

### Specific Aims

#### Aim 1

::: {.callout-tip icon="false" title="Recipes for TDA"}
Publish a [{recipes}](https://recipes.tidymodels.org) extension for ML vectorizations based on persistent homology.
:::

The new package will provide `step_*()` functions for several topological transformations and document the process for contributing additional steps. From among many proposed transformations [@fasy2020comparing;@pun2022persistent;@ali2023survey], we intend to include the following in a first release based on their relative simplicity, time on CRAN, frequency of use, and expected implementation cost: persistence statistics, Betti curve, lifespan curve (to be implemented anew), persistence landscape (to rely on the forthcoming [{plt}](https://corybrunson.github.io/plt/)), and persistent image (to be adapted from the original Matlab implementation^[https://github.com/CSU-TDA/PersistenceImages]). Dr. Brunson has experience writing an unpublished but installable {recipes} extension for association rules^[https://github.com/corybrunson/arulesteps].

#### Aim 2

::: {.callout-tip icon="false" title="Inference for TDA"}
Publish a [{flipr}](https://lmjl-alea.github.io/flipr/) extension for permutation-based statistical inference on topological data, compatible with Tidymodels workflows.
:::

Dr. Stamm leads a coordinated package collection for permutation-based inference, with the published {flipr} package at its center. This package features (i) implementations of classic permutation schemes that are agnostic to the type of input and (ii) the central [`PlausibilityFunction`](https://lmjl-alea.github.io/flipr/reference/PlausibilityFunction.html) [{R6}](https://r6.r-lib.org) class for seamless hypothesis testing and confidence estimation. Several extensions are published or in development for specific data types, including [{nevada}](https://astamm.github.io/nevada/) for network-valued data, [{fdatest}](https://github.com/astamm/fdatest) for functional data, and unpublished extensions for scalar- and vector-valued data. The new package will extend methods for two-sample testing, ANOVA, hypothesis testing, and confidence estimation to data types arising from TDA. It will inherit non-parametric combination [@pesarin2010permutation], which enables the use of several test statistics in a single hypothesis test, making the combination sensitive to different aspects of the compared underlying distributions.

#### Aim 3

::: {.callout-tip icon="false" title="Ripser for the R community"}
Refactor {ripserr} with a current implementation of Ripser and connect additional options to R.
:::

The base implementation of Ripser is written in C++, and {ripserr} provides integration via [{Rcpp}](https://www.rcpp.org). We therefore anticipate that this update will be a straightforward, though not trivial, exercise in C++/R integration. In particular, it will provide options to retrieve representative cycles and cocycles for topological features, which are essential for many practical applications.

## Progress Report

### Specific Aim 1

Development is ahead of schedule.
UIS and ALU have encouraged feature suggestions and plan continued development of {TDAvec}.
They have also suggested several improvements to {tdarec}.
JBR has scripted and validated source code generation for all {TDAvec} vectorizations in {tdarec}.
Remaining major tasks for {tdarec}---integration and deployment of additional persistent homology engines, implementation of hyperparameter tuners, and completion of longform documentation---should be completed within 2 months.

Key personnel:

* Jason Cory Brunson (JBR), Mathematician, University of Florida (UF)

Collaborators:

* Umar Islambekov (UIS), Data Scientist, Bowling Green State University (BGSU)
* Aleksei Luchinsky (ALU), Data Scientist, BGSU

Repositories:

* [{TDAvec}](https://github.com/uislambekov/TDAvec/)
* [{tdarec}](https://github.com/corybrunson/tdarec)

#### {TDAvec} development

JBR met with UIS and ALU on November 1 to discuss further development of {TDAvec} and coordination with {tdarec}.
Three specific goals were outlined for the coming months:

1. Implementation of additional vectorizations, with priority based on community input; see [issue #3](https://github.com/uislambekov/TDAvec/issues/3).
2. Provision of endpoint evaluation as well as interval integration for functions currently vectorized using only the latter; see [issue #2](https://github.com/uislambekov/TDAvec/issues/2).
This method is less lossy but only feasible (conditional on high efficiency) for suitable functions; unsuitable functions are already vectorized using endpoint evaluation.
3. Implementation of a feature weight optimization procedure developed by UIS.
Once completed, JBR will work to expose this feature to the {tdarec} interface, though it will not be a prerequisite for the first release.

#### {tdarec} development

##### Feature requests

UIS and ALU also made several important recommendations for {tdarec}:

1. Enable users to select (to the exclusion of others) or separate (into multiple list-columns) topological feature sets of different dimensions; see [issue #4](https://github.com/corybrunson/tdarec/issues/4).
2. Enable users to tune scale sequences (grids over which functions are vectorized) differently by topological feature dimension ($0, 1, 2, \ldots$) in addition to providing separate scale sequence tuners for both persistent diagram axes (birth vs death or birth vs persistence).
3. Consult the research literature and community on appropriate default values and ranges for hyperparameter tuners; see [issue #5](https://github.com/corybrunson/tdarec/issues/5).

Each of these will be addressed as {tdarec} development continues.

##### Common machine learning workflows using vectorizations of persistent homology

To assess typical applications in machine learning, JBR performed a simple bibliographic search to obtain 15 original studies and reviews thereof that used vectorizations of persistent homology.[^zotero-cases]
While the methodology of one study was not completely clear, in every other case analysis and modeling proceeded as follows: From each case was generated a distance matrix, image, or point cloud; each resulting data set had its persistent homology computed to obtain a persistence diagram; and each persistent diagram was transformed to a vector in some real feature space $\mathbb{R}^P$.
In a few cases, the vectorization had hyperparameters optimized over a training set before being applied to a testing set.
This reaffirmed our original assumptions and suggested no major adjustments to the design of {tdarec}.

[^zotero-cases]: <https://www.zotero.org/groups/2902167/r_packages/collections/U64SJ82I>

##### Source code generation

The script `build-tdavec-steps.R` in [the `build-pre` folder](https://github.com/corybrunson/tdarec/tree/main/build-pre) generates complete source code for recipe steps that call each vectorization from {TDAvec}; see [issue #3](https://github.com/corybrunson/tdarec/issues/3).
Only minor, if any, modifications will be needed to accommodate additions or changes to vectorizations and their parameters in {TDAvec} so long as existing package conventions are maintained.
JBR will work with UIS to address issues that arise from more substantive changes.

##### Engine deployment

Cubical and alpha persistent homology remain to be exposed as `step_*()` functions in {tdarec}, and logic remains to be scripted to deploy engines based on several user specifications; see [issue #1](https://github.com/corybrunson/tdarec/issues/1).
This is the primary goal for December.
Eventually, this will be done via dependency on [{phutil}](https://github.com/tdaverse/phutil), in development by MSI and AST.
However, it can be completed based on similar tools in [{ggtda}](https://github.com/tdaverse/ggtda) if development of {phutil} is not yet complete, then refactored after initial release.

##### Hyperparameter tuners

The next major goal is to write hyperparameter tuners for all {TDAvec} parameters; currently, the only tuner is for homological degree, in [`param-hom-degree.R`](https://github.com/corybrunson/tdarec/blob/main/R/param-hom-degree.R).
The only conceptual challenge lies with tuning the scale sequence, which may be controlled as a complete increasing numeric sequence or as a set of parameters for the endpoints and either the length or increment of the sequence, as with `base::seq()`.

##### Longform documentation

[The README](https://github.com/corybrunson/tdarec) contains a complete, illustrative exercise in machine learning, which applies vectorizations of persistent homology to the task of classifying point clouds generated from two different embeddings of the Klein bottle in $\mathbb{R}^4$.
JBR will mix expository text into the exercise before release.

Additionally, JBR will write a vignette that compares multiple vectorizations on an unrelated task using real-world data.
Tentatively, the vignette will use the MNIST handwritten digits data set[^mnist-digits]; a script to prepare a subset of these data for installation with {tdarec}, adapted from other users[^brendano-mnist], and the resulting data file are drafted in [the `mnist` branch](https://github.com/corybrunson/tdarec/tree/mnist).

[^mnist-digits]: <https://yann.lecun.com/exdb/mnist/>
[^brendano-mnist]: <https://gist.github.com/brendano/39760>

### Specific Aim 2

Key personnel:

- Manon Simonot (MSI), Statistical Engineer, National Centre for Scientific Research (CNRS)
- Aymeric Stamm (AST), Research Engineer, CNRS

#### MSI Contributions

##### Theoretical research on permutation tests

MSI read the following lectures:

- The lectures notes of Alessia Pini (Associate Professor, Department of Statistical Sciences, Università Cattolica del Sacro Cuore, Milano, Italy) called *Permutation Tests for Univariate and Multivariate
Data*.
- The lecture slides of Simone Vantini (Professor of Statistics, MOX Laboratory for Modeling and Scientific Computing, Dept. of Mathematics - Politecnico di Milano, Italy) called *Permutation Tests*.
- The lecture slides of AST called *Inference for populations of complex objects*.

She also read the following articles referenced by [{flipr}](https://lmjl-alea.github.io/flipr/):

- Fraser, D. A. S. 2019. “The p-Value Function and Statistical Inference.” The American
Statistician 73 (sup1): 135–47. <https://doi.org/10.1080/00031305.2018.1556735>.
- Infanger, Denis, and Arno Schmidt-Trucksäss. 2019. “P Value Functions: An Underused Method to Present Research Results and to Promote Quantitative Reasoning.” Statistics in Medicine 38
(21): 4189–97. <https://doi.org/10.1002/sim.8293>.
- Martin, Ryan. 2017. “A Statistical Inference Course Based on p-Values.” The American
Statistician 71 (2): 128–36. <https://doi.org/10.1080/00031305.2016.1208629>.

Finally, she read all the vignettes on [{flipr}](https://lmjl-alea.github.io/flipr/)'s website:

- Get started
- The alternative hypothesis in permutation testing - On the exactness of permutation tests
- Computing plausibility functions

That allowed her to understand how tests by permutations are working, and more precisely which test statistics and ways of permuting data can be used based on the populations and the goals of the tests.

##### Implementation of permutation tests using base R

She dived into the code written in base R (from Alessia Pini and Simone Vantini) that implements the following tests:

- Two univariate populations: independent
- Two multivariate populations: independent and paired
- One multivariate population
- ANOVA (One way, two way) and M-ANOVA
- Linear regression: global test on all coefficients and test on each coefficient

That allowed her to understand how to implement these different tests, which will allow her to add the ANOVA and the tests on regression coefficients in [{flipr}](https://lmjl-alea.github.io/flipr/).

##### Exploration of how [{flipr}](https://lmjl-alea.github.io/flipr/) works

Use of the [`PlausibilityFunction`](https://lmjl-alea.github.io/flipr/reference/PlausibilityFunction.html) R6 class to do the following tests: 

- Test on two univariate population means
- Test on two univariate populations means and variances
- Test on one univariate population mean

That allowed her to understand the implementation of the [{flipr}](https://lmjl-alea.github.io/flipr/) package, how users can use it to perform tests already implemented in flipr and how developers can use it to implement tests for their own complex data.

##### Learning the [**futureverse**](https://www.futureverse.org)

She followed the online tutorial <https://astamm.github.io/futureverse/> to learn how to use the [**futureverse**](https://www.futureverse.org) ecosystem of packages to parallelize code. This is intended to be used for reducing computation time in [{flipr}](https://lmjl-alea.github.io/flipr/).

#### AST Contributions

In addition to MSI supervision, AST focused on the implementation of the soon-to-be {phutil} package (stands for **P**ersistence **H**omology **Util**ities and should be pronounced *futile*), for a TDAverse-opinionated data structure that stores PH data and a number of utility functions to be used by reverse dependencies. Once available, it should be a direct reverse dependency of the {plt} package, which will be the occasion to test and report back on {plt} and {tdarec}.

::: {.callout-note title="Survey of existing classes for PH"}
A survey of existing classes to host persistence homology (PH) revealed the following three classes:

- the `diagram` class in {TDA}, to which belongs the `diagram` element of the list output of, e.g., `ripsDiag()`; it is a 3-column matrix with attributes for the maximum dimension and the maximum scale (radius);
- the `PHom` class in {ripserr}, which is a light wrapper around a 3-column data frame;
- the `persistence` class in {plt}, which is structured as a list whose first element is a list of 2-column matrices and whose other elements are the prime field of coefficients, the maximum dimension, and the maximum scale.

Hence, PH is stored either as a matrix or a data frame and metadata are stored as attributes or additional elements of a list whose first element contains PH data.
:::

::: {.callout-warning title="Missing features"}
- None of the above includes possibility of storing extended PH.
- None of the above keeps track of how the diagram was computed (which filtration, which engine to perform computations, and so on). 
:::

Storing the diagram as data frame with columns birth, death and maybe dimension generates an overhead and the dimension will be duplicated to store it for each point. Using a list of 2-column matrices seems to be the most memory-efficient strategy. Each element of that list would store the points corresponding to a specific dimension. Extended persistence could be encoded in the following ways:

(1) we might encode type using signs (+ vs –), except that filtration values could be negative, yielding negative births and/or deaths in general settings, so the signs would be serving a different purpose;
(2) we could store a list of pairs of 2-column matrices, where the length of the list is the maximum degree + 1 and each element is a length-2 list of 2-column matrices, the first one storing ordinary & relative features and the second one storing extended features;
(3) we could flag the extended features using an integer or logical attribute indicating which matrix rows are extended.

Only the last two options are viable. The second option complexifies the data structure but achieves the lowest memory footprint.

::: {.callout-tip title="Proposed data structure"}
We propose to use a list of pairs of 2-columns matrices to store PH data. Other metadata will be stored as attributes. That includes prime field of coefficients, maximum dimension, maximum scale (radius), data preprocessing pipeline used to compute PH data (filtration, simplicial complex, engine used to perform computations). Extended persistence will be stored in the second 2-column matrix of each element of the outer list.
:::

Keeping track of preprocessing steps used to get the PH data

: We will take inspiration from {recipes}. A simple solution could be to store as attribute the recipe object created by the {tdarec} package. However, we should provide the user with the possiblity of coercing the PH data into the proposed data structure which he might have obtained without a recipe from {tdarec}. This raises the question of how to allow the user to provide the information about preprocessing steps and how store that information.

List of S3 methods to implement for the proposed class

: When defining a new class in R, it is important to implement a number of S3 methods. In particular:

    - a number of functions to coerce existing data structures that store PH data into the proposed data structure;
    - `format()`, which in turn influences the way the object is printed in the console;
    - subset operators;
    - `as.matrix()`, `as.data.frame()`, and `as_tibble()` to coerce the proposed data structure into the data structures assumed by many applications.

    Other S3 methods could be relevant since the proposed data structure ains at being shared by a collection of R packages that work well together for performing statistics on topological data. We will investigate which methods have been implemented in the {tibble} package which, similarly, implements a data structure for storing data which is shared across the Tidyverse collection of packages.

    A number of S3 methods will need to be implemented as well to handle extended persistence. For instance, one might want to focus on ordinary/relative features or extended features, extract them, simplify the data structure in case extended features do not exist, combine both information and so on.

### Specific Aim 3

Development is on schedule, taking into account the Thanksgiving break and three weeks of leave by JBR.
The student research assistants have trained in the essential mathematical and computational background to proceed with development, including validation of hand-worked exercises against Ripser output.
They have joined the {ripserr} repository as collaborators and forked the Ripser C++ library to study its structure and processes.
The first phase of development is underway as a direct {Rcpp} adaptation of the current Ripser library, rather than as a revision of the current {ripserr} R package.

Key personnel:

* Jason Cory Brunson (JBR), Mathematician, UF
* Kent Phipps (KPH), undergraduate student, UF
* Sean Hershkowitz (SHE), undergraduate student, UF
* Alice Zhang (AZH), undergraduate student, UF

Repositories:

* [Ripser fork](https://github.com/strongKs/ripser)
* [{ripserr}](https://github.com/tdaverse/ripserr/)

#### Research assistant training

##### Mathematical and computational background

The RAs (KPH, SHE, and AZH) have completed a brief series of lectures with exercises (from JBR) on the mathematical theory of singular homology.
They have also read (at a high level) several manuscripts about persistent homology and the efficiencies used by Ripser that will be key references for the duration [@desilva2011dualities; @chen2011persistent; @bauer2021ripser; @pham2023wagner].
Finally, they have gained proficiency in the calculation---by hand---of persistent homology for small point clouds (distance matrices derived from coordinate matrices).
As validation, they have replicated these examples using the command line Ripser tool.
They will continue with similar exercises as development continues.

##### Familiarization with Ripser

In addition to validation against manual examples, the RAs have extensively explored Ripser via direct inspection and checkpoint execution in debug mode.
They have prepared detailed documentation of the library that will guide the adaptation.[^ripser-structure]

[^ripser-structure]: <https://docs.google.com/document/d/1Mi7PxgvZuYiu_fubsw8J5UYhxCJyWM0UBCa29hJrbsk/> -- While it is not public, then we will share the document upon request.

#### {ripserr} development

##### {Rcpp} packaging of C++ library

The RAs considered two approaches to a first upgrade: "fitting" the current Ripser library into the existing {ripserr} package, or building an {Rcpp} wrapper from scratch.
They decided on the latter approach; an export to R via {Rcpp} is being drafted in [the `first-transition-to-R` branch](https://github.com/StrongKs/ripser/tree/first-transition-to-R) of KPH's fork of the Ripser repo.
Upon completion, the reorganized and R-exported code will be grafted to a branch of {ripserr}, replacing the current [`ripser_short.cpp`](https://github.com/tdaverse/ripserr/blob/main/src/ripser_short.cpp) source.

## References
